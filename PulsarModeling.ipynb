{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('HTRU_2.csv', names=['IP_mean', 'IP_deviation', 'IP_kurtosis', 'IP_skew', 'DMSNR_mean', 'DMSNR_deviation',\n",
    "                                       'DMSNR_kurtosis', 'DMSNR_skew', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class distribution\n",
    "\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the original SMOTE paper in 2011 (https://arxiv.org/abs/1106.1813), SMOTE is best used when combined with random undersampling. I chose to begin with random undersampling in order to limit the danger of my minority class being lost in the volume of majority instances at the time of SMOTE implemenation. My data class ratio was initially at 1:10 which I trimmed to 1:3 using random undersampling.\n",
    "\n",
    "After undersampling, I used SMOTE to complete the process of evening my class instances by bringing the ratio down to 1:1.\n",
    "\n",
    "I chose not to use pipelines here to allow for neat compartmentalization and quick verification of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['IP_mean', 'IP_deviation', 'IP_kurtosis', 'IP_skew', 'DMSNR_mean',\n",
    "       'DMSNR_deviation', 'DMSNR_kurtosis', 'DMSNR_skew']]\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 5463, 1: 1639})\n"
     ]
    }
   ],
   "source": [
    "# random undersampling to trim majority class, class imbalance will go from 1:10 to 1:3.\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.3, random_state=2)\n",
    "xTrain, yTrain = rus.fit_resample(x, y)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 5463, 1: 2731})\n"
     ]
    }
   ],
   "source": [
    "# smote to beef up minority class (1), class imbalance will go from 1:3 to 1:1.\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=2)\n",
    "xTrain, yTrain = smote.fit_sample(xTrain, yTrain)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale our resampled training data\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(xTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard kfold validation on\n",
    "\n",
    "Y = yTrain\n",
    "\n",
    "kfd = KFold(10)\n",
    "\n",
    "def kfold(model, score_type) :\n",
    "    kfold_scores = []\n",
    "    \n",
    "    for train_index, test_index in kfd.split(X, Y):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        clf = model()\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        score = score_type(Y_test, Y_pred)\n",
    "        kfold_scores.append(score)\n",
    "        \n",
    "    \n",
    "    print(sum(kfold_scores)/len(kfold_scores))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic Regression\n",
    "\n",
    "lr_rcScore = kfold(LogisticRegression, recall_score)\n",
    "lr_pcScore = kfold(LogisticRegression, precision_score)\n",
    "lr_acScore = kfold(LogisticRegression, accuracy_score)\n",
    "lr_f1Score = kfold(LogisticRegression, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "svc_rcScore = kfold(SVC, recall_score)\n",
    "svc_pcScore = kfold(SVC, precision_score)\n",
    "svc_acScore = kfold(SVC, accuracy_score)\n",
    "svc_f1Score = kfold(SVC, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "gnb_rcScore = kfold(GaussianNB, recall_score)\n",
    "gnb_pcScore = kfold(GaussianNB, precision_score)\n",
    "gnb_acScore = kfold(GaussianNB, accuracy_score)\n",
    "gnb_f1Score = kfold(GaussianNB, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "knn_rcScore = kfold(KNeighborsClassifier, recall_score)\n",
    "knn_pcScore = kfold(KNeighborsClassifier, precision_score)\n",
    "knn_acScore = kfold(KNeighborsClassifier, accuracy_score)\n",
    "knn_f1Score = kfold(KNeighborsClassifier, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVC\n",
    "\n",
    "lsvc_rcScore = kfold(LinearSVC, recall_score)\n",
    "lsvc_pcScore = kfold(LinearSVC, precision_score)\n",
    "lsvc_acScore = kfold(LinearSVC, accuracy_score)\n",
    "lsvc_f1Score = kfold(LinearSVC, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd_rcScore = kfold(SGDClassifier, recall_score)\n",
    "sgd_pcScore = kfold(SGDClassifier, precision_score)\n",
    "sgd_acScore = kfold(SGDClassifier, accuracy_score)\n",
    "sgd_f1Score = kfold(SGDClassifier, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dtc_rcScore = kfold(DecisionTreeClassifier, recall_score)\n",
    "dtc_pcScore = kfold(DecisionTreeClassifier, precision_score)\n",
    "dtc_acScore = kfold(DecisionTreeClassifier, accuracy_score)\n",
    "dtc_f1Score = kfold(DecisionTreeClassifier, f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "rfc_rcScore = kfold(RandomForestClassifier, recall_score)\n",
    "rfc_pcScore = kfold(RandomForestClassifier, precision_score)\n",
    "rfc_acScore = kfold(RandomForestClassifier, accuracy_score)\n",
    "rfc_f1Score = kfold(RandomForestClassifier, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = pd.DataFrame({'Model': ['Logistic Regression', 'Support Vector Machines', 'Naive Bayes','KNN', \n",
    "                                 'Linear SVC', 'Stochastic Gradient Decent', 'Decision Tree', 'Random Forest'], \n",
    "                       'Recall_Score' : [lr_rcScore, svc_rcScore, gnb_rcScore, knn_rcScore, lsvc_rcScore, sgd_rcScore,\n",
    "                                 dtc_rcScore, rfc_rcScore],\n",
    "                       'Precision_Score' : [lr_pcScore, svc_pcScore, gnb_pcScore, knn_pcScore, lsvc_pcScore, sgd_pcScore,\n",
    "                                 dtc_pcScore, rfc_pcScore],\n",
    "                       'Accuracy_Score' : [lr_acScore, svc_acScore, gnb_acScore, knn_acScore, lsvc_acScore, sgd_acScore,\n",
    "                                 dtc_acScore, rfc_acScore],\n",
    "                       'F1_Score' : [lr_f1Score, svc_f1Score, gnb_f1Score, knn_f1Score, lsvc_f1Score, sgd_f1Score,\n",
    "                                 dtc_f1Score, rfc_f1Score]})\n",
    "\n",
    "models_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont ferogt all the satudd you said in the notes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
